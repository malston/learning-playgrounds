# AI Agent Architecture

## Input

See [prompt.md](prompt.md)

## Output

See [results.md](results.md)

## Try It Out

```sh
cat <(echo "/playground") prompt.md | CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000 claude --dangerously-skip-permissions
```

## Full Transcript

```text
âœ»
    |
   â–Ÿâ–ˆâ–™     Claude Code v2.1.45
 â–â–›â–ˆâ–ˆâ–ˆâ–œâ–Œ   Opus 4.6 Â· Claude Max
â–â–œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–›â–˜  ~/code/learning-playgrounds/ai-agent-architecture
  â–˜â–˜ â–â–
  â¿ Â SessionStart:startup says: [ai-agent-architecture] recent context, 2026-02-18 9:38am MST
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

     Legend: session-request | ğŸ”´ bugfix | ğŸŸ£ feature | ğŸ”„ refactor | âœ… change | ğŸ”µ discovery | âš–ï¸ decision

     Column Key
       Read: Tokens to read this observation (cost to learn it now)
       Work: Tokens spent on work that produced this record ( research, building, deciding)

     Context Index: This semantic index (titles, types, files, tokens) is usually sufficient to understand past work.

     When you need implementation details, rationale, or debugging context:
       - Use MCP tools (search, get_observations) to fetch full observations on-demand
       - Critical types ( bugfix, decision) often need detailed fetching
       - Trust this index over re-reading code for past decisions and learnings

     Context Economics
       Loading: 3 observations (1,520 tokens to read)
       Work investment: 7,016 tokens spent on research, building, and decisions
       Your savings: 5,496 tokens (78% reduction from reuse)

     Feb 18, 2026

     ai-agent-architecture.html
       #22614  9:29 AM  ğŸŸ£  Interactive AI Agent Architecture Explorer Built
         A comprehensive interactive learning tool was built to teach AI agent architecture through visual concept mapping. The explorer presents core agent patterns
     (routing, orchestration, delegation, reflection) alongside foundational concepts (LLM, chatbot vs agent distinctions) and architectural choices (single vs
     multi-agent systems). The interface uses an interactive node-link diagram where learners can track their understanding level for each concept, rearrange nodes to
     match their mental models, and generate personalized learning prompts based on knowledge gaps. This transforms abstract agent architecture concepts into concrete,
      explorable patterns with actual pseudocode examples mapped to implementation approaches.
         (~444t) (ğŸ› ï¸ 1,116t)


     prompt.md
       #22615           ğŸ”µ  AI Agent Architecture Learning Playground Project Structure Analyzed
         The AI Agent Architecture learning playground is a previous effort to create an interactive tool for teaching agent architecture concepts. It consists of a
     prompt defining learning objectives (routing, orchestration, delegation patterns; agent vs chatbot distinctions; single vs multi-agent systems; code mapping), a
     results file documenting what was built, and a README with full transcript. The core deliverable was a 608-line HTML interactive concept map with 15 nodes
     spanning foundational concepts, components, patterns, and architectural systems. The tool enables learners to track their understanding level for each concept,
     rearrange nodes visually, view pseudocode implementations, and generate personalized learning paths based on knowledge gaps. The project demonstrates a "learning
     by exploration" approach using an interactive concept map rather than linear documentation.
         (~500t) (ğŸ” 1,068t)

       #22616  9:30 AM  ğŸ”µ  Conversation History Shows Interactive Playground Already Generated
         The conversation archive reveals that an interactive concept map explorer was previously built to teach AI agent architecture. The artifact is a 608-line HTML
      file with embedded styling and JavaScript that provides interactive learning through a visual concept map with 15 nodes spanning Foundation (LLM, Chatbot,
     Agent), Components (Tool Use, Memory, Planning), Patterns (Routing, Orchestration, Delegation, Reflection), Systems (Single-Agent, Multi-Agent), and Roles
     (Supervisor, Worker, Evaluator). The interface allows learners to click nodes for details and pseudocode, track their knowledge level for each concept, rearrange
     node positions to build personal mental models, use preset learning configurations, and generate personalized learning prompts based on knowledge gaps. The
     generation required working around Claude's output token limits by increasing the CLAUDE_CODE_MAX_OUTPUT_TOKENS configuration. The current session is determining
     whether this interactive playground meets the learning goal or if additional formats (written walkthrough, runnable code examples) would be more valuable.
         (~576t) (ğŸ” 4,832t)



     Access 7k tokens of past research & decisions for just 1,520t. Use MCP search tools to access memories by ID.

     View Observations Live @ http://localhost:37777












â¯ /playground
  # Prompt

  Teach me how AI agents actually work. Not the buzzwords. The architecture. How routing, orchestration, and delegation actually fit together. For example:

  - What makes an agent different from a chatbot
  - 4 core patterns (routing, orchestration, delegation, reflection)
  - When to use single vs multi-agent systems                                                                                                                            - How each pattern maps to actual code
                                                                                                                                                                       âº Skill(playground)
  â¿ Â Successfully loaded skill

âº Using the playground skill to build an interactive concept map explorer for AI agent architecture.

  Let me load the concept-map template first.

âº Searched for 1 pattern, read 2 files (ctrl+o to expand)

âº I see there was a previous version of this playground. Let me check what currently exists.

âº Searched for 1 pattern (ctrl+o to expand)

âº Bash(git log --oneline -5)
  â¿ Â 46a1f71 Fix the command
     463b057 Remove generated content
     ccb6451 Restructure content
     â€¦ +2 lines (ctrl+o to expand)

âº The previous HTML was removed. I'll build a fresh one from scratch, incorporating improvements. Let me also handle the uncommitted changes first per the version
  control rules.

âº Bash(git status)
  â¿ Â On branch main
     Your branch is up to date with 'origin/main'.

     nothing to commit, working tree clean

âº Clean tree, good. Now let me build the playground. This is a concept-map style interactive explorer -- I'll follow the template closely.

âº Write(ai-agent-architecture.html)
  â¿ Â Wrote 858 lines to ai-agent-architecture.html
       1 <!DOCTYPE html>
       2 <html lang="en">
       3 <head>
       4 <meta charset="UTF-8">
       5 <meta name="viewport" content="width=device-width, initial-scale=1.0">
       6 <title>AI Agent Architecture Explorer</title>
       7 <style>
       8 *{margin:0;padding:0;box-sizing:border-box}
       9 :root{
      10   --bg:#0d1117;--surface:#161b22;--border:#30363d;
     â€¦ +848 lines (ctrl+o to expand)

âº Bash(open /Users/markalston/code/learning-playgrounds/ai-agent-architecture/ai-agent-architecture.html)
  â¿ Â (No output)

âº The playground is open in your browser, Mark. Here's what you've got:

  Interactive concept map with 15 nodes across 5 categories:
  - Foundation: LLM â†’ Chatbot â†’ Agent (the progression from raw model to autonomous agent)
  - Components: Tool Use, Memory, Planning (what agents are made of)
  - Patterns: Routing, Orchestration, Delegation, Reflection (the 4 architectural patterns)
  - Systems: Single-Agent vs Multi-Agent (when to use which)
  - Roles: Supervisor, Worker, Evaluator (who does what in multi-agent systems)

  How to use it:
  - Click any node to see its description, real pseudocode, when to use it, and its connections
  - Click the colored dot on a node to cycle knowledge level (Know / Fuzzy / Unknown)
  - Drag nodes to rearrange the map to match your mental model
  - Use presets at the top ("I'm new", "I know chatbots", etc.) to quickly set knowledge levels
  - Copy the prompt at the bottom -- it builds a personalized learning request based on your knowledge gaps

  Each node includes concrete implementation code showing how the pattern actually works, not just theory.

âœ» Crunched for 3m 34s

â¯ /exit
  â¿  See ya!

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â¯Â 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  [OpusÂ 4.6Â |Â Max]Â â”‚Â ai-agent-architectureÂ git:(main*)                                                                                                 â§‰ In README.md
  ContextÂ â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘Â 31%Â â”‚Â UsageÂ â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘Â 13%Â (1hÂ 19mÂ /Â 5h)
  âµâµ bypass permissions on (shift+tab to cycle) Â· 2 files +3 -0

Resume this session with:
claude --resume c98a1d9a-c627-4d7c-9728-54941ac45f80
â˜¸ cluster01 (kube-system) learning-playgrounds/ai-agent-architecture ğŸŒ± main [!?][â± 39m13s]
â¯ cd ../llm-inference-infrastructure
â˜¸ cluster01 (kube-system) learning-playgrounds/llm-inference-infrastructure ğŸŒ± main [!?]
â¯ cat <(echo "/playground") prompt.md | CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000 claude --dangerously-skip-permissions

â•­â”€â”€â”€ Claude Code v2.1.45 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                      â”‚ Tips for getting started                                                                                                     â”‚
â”‚          Welcome back Mark!          â”‚ Run /init to create a CLAUDE.md file with instructions for Claude                                                            â”‚
â”‚                                      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                            â”‚
â”‚                                      â”‚ Recent activity                                                                                                              â”‚
â”‚                                      â”‚ No recent activity                                                                                                           â”‚
â”‚                   âœ»                  â”‚                                                                                                                              â”‚
â”‚                   |                  â”‚                                                                                                                              â”‚
â”‚                  â–Ÿâ–ˆâ–™                 â”‚                                                                                                                              â”‚
â”‚                â–â–›â–ˆâ–ˆâ–ˆâ–œâ–Œ               â”‚                                                                                                                              â”‚
â”‚               â–â–œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–›â–˜              â”‚                                                                                                                              â”‚
â”‚                 â–˜â–˜ â–â–                â”‚                                                                                                                              â”‚
â”‚        Opus 4.6 Â· Claude Max         â”‚                                                                                                                              â”‚
â”‚   ~/â€¦/llm-inference-infrastructure   â”‚                                                                                                                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  â¿ Â SessionStart:startup says: [llm-inference-infrastructure] recent context, 2026-02-18 10:17am MST
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

     No previous sessions found for this project yet.

     View Observations Live @ http://localhost:37777

â¯ /playground
  # LLM Inference Infrastructure Playground

  Build an interactive learning playground that teaches the core concepts of LLM inference infrastructure â€” hardware, memory, quantization, parallelism, and
  deployment decisions â€” through hands-on exploration.

  ## Learning Goals

  By the end, the learner should be able to:

  - Estimate VRAM requirements for any model size and precision
  - Understand why quantization works and when it hurts quality
  - Explain the difference between tensor, pipeline, and data parallelism â€” and when to use each
  - Navigate the buy vs. rent vs. reserved instance decision
  - Understand MoE vs. dense model tradeoffs

  ## Core Interactive Elements

  ### 1. VRAM Calculator

  An interactive calculator where the user selects:

  - Model size (7B, 13B, 70B, 405B, 745B MoE)
  - Precision format (FP32, BF16/FP16, FP8, INT4)
  - Number of concurrent users
  - Context window size

  Output: total VRAM needed (weights + KV cache + overhead), hardware recommendations from the GPU reference table, and whether it fits on a single node or
  requires multi-node parallelism.

  ### 2. Quantization Trade-off Explorer

  Visual slider or selector that shows:

  - Memory footprint at each precision level for a chosen model
  - Quality impact (Safe / Caution / Noticeable degradation)
  - Speed impact
  - Concrete byte-level example showing how a weight value changes from FP32 â†’ INT4

  ### 3. Parallelism Strategy Visualizer

  An animated or interactive diagram showing how a model is split across GPUs for:

  - Tensor Parallelism (layers split horizontally across GPUs)
  - Pipeline Parallelism (layers split vertically, GPUs in sequence)
  - Data Parallelism (full model copies, different requests)

  User selects a model size and GPU count, and the playground recommends the right strategy with a visual explanation of why.

  ### 4. Buy vs. Rent Decision Tool

  Interactive decision tree / calculator:

  - Input: estimated inference volume (requests/day), model size, compliance requirements
  - Output: recommended path (buy / reserved / on-demand) with cost comparison
  - Show the breakeven math dynamically

  ### 5. MoE vs. Dense Comparison

  Side-by-side visualization of a dense 70B model vs. a MoE 745B model showing:

  - Active parameters per token (compute cost)
  - Total parameters loaded (memory cost)
  - How the router selects experts

  ## Style & UX

  - Dark theme, clean and modern
  - Sections flow top to bottom but each is self-contained
  - Key terms have inline tooltips on hover (e.g., hover "KV cache" â†’ short definition)
  - No quizzes â€” this is a reference tool for practitioners, not a course
  - Show the math, don't hide it â€” engineers want to see the formulas

  ## Audience

  Platform engineers and infrastructure architects who are new to ML infrastructure but comfortable with systems concepts (memory, networking, distributed
  systems). They understand what a GPU is but have never had to size one for an LLM workload.


âº Skill(playground)
  â¿ Â Successfully loaded skill

âº Using the playground skill to build this. Let me first check the project state and load the template.

âº Bash(git status && echo "---" && ls -la)
  â¿ Â On branch main
     Your branch is up to date with 'origin/main'.
     â€¦ +16 lines (ctrl+o to expand)

âº Searched for 1 pattern, read 2 files (ctrl+o to expand)

âº Mark, before I start building -- a quick note on git. You've got uncommitted changes in ../ai-agent-architecture/ (modified prompt.md and untracked
  agent-architecture-prompt.md). Those are in a sibling project so they won't interfere, but you may want to commit them separately. I'll create a feature branch for
  this work.

âº Bash(cd /Users/markalston/code/learning-playgrounds && git checkout -b feature/llm-inference-playground)
  â¿ Â Switched to a new branch 'feature/llm-inference-playground'
  â¿ Â Shell cwd was reset to /Users/markalston/code/learning-playgrounds/llm-inference-infrastructure

âº Now let me build the playground. This is a substantial single-file HTML application with 5 interactive sections.

âœ³ Accomplishingâ€¦ (10m 28s Â· â†“ 36.7k tokens Â· thought for 68s)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â¯Â 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  [OpusÂ 4.6Â |Â Max]Â â”‚Â llm-inference-infrastructureÂ git:(feature/llm-inference-playground)                                                               â§‰ In prompt.md
  ContextÂ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘Â 39%Â â”‚Â UsageÂ â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘Â 15%Â (33mÂ /Â 5h)
  âµâµ bypass permissions on (shift+tab to cycle)
```
